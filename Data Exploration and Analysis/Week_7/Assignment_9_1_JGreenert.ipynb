{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 9\n",
    "\n",
    "Examples and Exercises from Think Stats, 2nd Edition\n",
    "\n",
    "http://thinkstats2.com\n",
    "\n",
    "Copyright 2016 Allen B. Downey\n",
    "\n",
    "MIT License: https://opensource.org/licenses/MIT\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os.path import basename, exists\n",
    "\n",
    "\n",
    "def download(url):\n",
    "    filename = basename(url)\n",
    "    if not exists(filename):\n",
    "        from urllib.request import urlretrieve\n",
    "\n",
    "        local, _ = urlretrieve(url, filename)\n",
    "        print(\"Downloaded \" + local)\n",
    "\n",
    "\n",
    "download(\"https://github.com/AllenDowney/ThinkStats2/raw/master/code/thinkstats2.py\")\n",
    "download(\"https://github.com/AllenDowney/ThinkStats2/raw/master/code/thinkplot.py\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import random\n",
    "\n",
    "import thinkstats2\n",
    "import thinkplot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hypothesis testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following is a version of `thinkstats2.HypothesisTest` with just the essential methods:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HypothesisTest(object):\n",
    "\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "        self.MakeModel()\n",
    "        self.actual = self.TestStatistic(data)\n",
    "\n",
    "    def PValue(self, iters=1000):\n",
    "        self.test_stats = [self.TestStatistic(self.RunModel()) \n",
    "                           for _ in range(iters)]\n",
    "\n",
    "        count = sum(1 for x in self.test_stats if x >= self.actual)\n",
    "        return count / iters\n",
    "\n",
    "    def TestStatistic(self, data):\n",
    "        raise UnimplementedMethodException()\n",
    "\n",
    "    def MakeModel(self):\n",
    "        pass\n",
    "\n",
    "    def RunModel(self):\n",
    "        raise UnimplementedMethodException()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And here's an example that uses it to compute the p-value of an experiment where we toss a coin 250 times and get 140 heads."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CoinTest(HypothesisTest):\n",
    "\n",
    "    def TestStatistic(self, data):\n",
    "        heads, tails = data\n",
    "        test_stat = abs(heads - tails)\n",
    "        return test_stat\n",
    "\n",
    "    def RunModel(self):\n",
    "        heads, tails = self.data\n",
    "        n = heads + tails\n",
    "        sample = [random.choice('HT') for _ in range(n)]\n",
    "        hist = thinkstats2.Hist(sample)\n",
    "        data = hist['H'], hist['T']\n",
    "        return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The p-value turns out to be about 7%, which is considered on the border of statistical significance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.068"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ct = CoinTest((140, 110))\n",
    "pvalue = ct.PValue()\n",
    "pvalue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Permutation test\n",
    "\n",
    "To compute the p-value of an observed difference in means, we can assume that there is no difference between the groups and generate simulated results by shuffling the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DiffMeansPermute(thinkstats2.HypothesisTest):\n",
    "\n",
    "    def TestStatistic(self, data):\n",
    "        group1, group2 = data\n",
    "        test_stat = abs(group1.mean() - group2.mean())\n",
    "        return test_stat\n",
    "\n",
    "    def MakeModel(self):\n",
    "        group1, group2 = self.data\n",
    "        self.n, self.m = len(group1), len(group2)\n",
    "        self.pool = np.hstack((group1, group2))\n",
    "\n",
    "    def RunModel(self):\n",
    "        np.random.shuffle(self.pool)\n",
    "        data = self.pool[:self.n], self.pool[self.n:]\n",
    "        return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's an example where we test the observed difference in pregnancy length for first babies and others."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "download(\"https://github.com/AllenDowney/ThinkStats2/raw/master/code/nsfg.py\")\n",
    "download(\"https://github.com/AllenDowney/ThinkStats2/raw/master/code/first.py\")\n",
    "download(\"https://github.com/AllenDowney/ThinkStats2/raw/master/code/2002FemPreg.dct\")\n",
    "download(\n",
    "    \"https://github.com/AllenDowney/ThinkStats2/raw/master/code/2002FemPreg.dat.gz\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import first\n",
    "\n",
    "live, firsts, others = first.MakeFrames()\n",
    "data = firsts.prglngth.values, others.prglngth.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The p-value is about 17%, which means it is plausible that the observed difference is just the result of random sampling, and might not be generally true in the population."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.168"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ht = DiffMeansPermute(data)\n",
    "pvalue = ht.PValue()\n",
    "pvalue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's the distrubution of the test statistic (the difference in means) over many simulated samples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ht.PlotCdf()\n",
    "thinkplot.Config(xlabel='test statistic',\n",
    "                   ylabel='CDF')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Under the null hypothesis, we often see differences bigger than the observed difference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DiffMeansOneSided(DiffMeansPermute):\n",
    "\n",
    "    def TestStatistic(self, data):\n",
    "        group1, group2 = data\n",
    "        test_stat = group1.mean() - group2.mean()\n",
    "        return test_stat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the hypothesis under test is that first babies come late, the appropriate test statistic is the raw difference between first babies and others, rather than the absolute value of the difference.  In that case, the p-value is smaller, because we are testing a more specific hypothesis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.083"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ht = DiffMeansOneSided(data)\n",
    "pvalue = ht.PValue()\n",
    "pvalue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But in this example, the result is still not statistically significant."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Difference in standard deviation\n",
    "\n",
    "In this framework, it is easy to use other test statistics.  For example, if we think the variance for first babies might be higher, we can run this test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DiffStdPermute(DiffMeansPermute):\n",
    "\n",
    "    def TestStatistic(self, data):\n",
    "        group1, group2 = data\n",
    "        test_stat = group1.std() - group2.std()\n",
    "        return test_stat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.077"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ht = DiffStdPermute(data)\n",
    "pvalue = ht.PValue()\n",
    "pvalue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But that's not statistically significant either."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing correlation\n",
    "\n",
    "To check whether an observed correlation is statistically significant, we can run a permutation test with a different test statistic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CorrelationPermute(thinkstats2.HypothesisTest):\n",
    "\n",
    "    def TestStatistic(self, data):\n",
    "        xs, ys = data\n",
    "        test_stat = abs(thinkstats2.Corr(xs, ys))\n",
    "        return test_stat\n",
    "\n",
    "    def RunModel(self):\n",
    "        xs, ys = self.data\n",
    "        xs = np.random.permutation(xs)\n",
    "        return xs, ys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's an example testing the correlation between birth weight and mother's age."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned = live.dropna(subset=['agepreg', 'totalwgt_lb'])\n",
    "data = cleaned.agepreg.values, cleaned.totalwgt_lb.values\n",
    "ht = CorrelationPermute(data)\n",
    "pvalue = ht.PValue()\n",
    "pvalue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "The reported p-value is 0, which means that in 1000 trials we didn't see a correlation, under the null hypothesis, that exceeded the observed correlation.  That means that the p-value is probably smaller than $1/1000$, but it is not actually 0.\n",
    "\n",
    "To get a sense of how unexpected the observed value is under the null hypothesis, we can compare the actual correlation to the largest value we saw in the simulations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.06883397035410904, 0.048747665104395835)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ht.actual, ht.MaxTestStat()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing proportions\n",
    "\n",
    "Here's an example that tests whether the outcome of a rolling a six-sided die is suspicious, where the test statistic is the total absolute difference between the observed outcomes and the expected long-term averages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DiceTest(thinkstats2.HypothesisTest):\n",
    "\n",
    "    def TestStatistic(self, data):\n",
    "        observed = data\n",
    "        n = sum(observed)\n",
    "        expected = np.ones(6) * n / 6\n",
    "        test_stat = sum(abs(observed - expected))\n",
    "        return test_stat\n",
    "\n",
    "    def RunModel(self):\n",
    "        n = sum(self.data)\n",
    "        values = [1, 2, 3, 4, 5, 6]\n",
    "        rolls = np.random.choice(values, n, replace=True)\n",
    "        hist = thinkstats2.Hist(rolls)\n",
    "        freqs = hist.Freqs(values)\n",
    "        return freqs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's an example using the data from the book:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1242"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = [8, 9, 19, 5, 8, 11]\n",
    "dt = DiceTest(data)\n",
    "pvalue = dt.PValue(iters=10000)\n",
    "pvalue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The observed deviance from the expected values is not statistically significant.\n",
    "\n",
    "By convention, it is more common to test data like this using the chi-squared statistic:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DiceChiTest(DiceTest):\n",
    "\n",
    "    def TestStatistic(self, data):\n",
    "        observed = data\n",
    "        n = sum(observed)\n",
    "        expected = np.ones(6) * n / 6\n",
    "        test_stat = sum((observed - expected)**2 / expected)\n",
    "        return test_stat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using this test, we get a smaller p-value:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.042"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt = DiceChiTest(data)\n",
    "pvalue = dt.PValue(iters=10000)\n",
    "pvalue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Taking this result at face value, we might consider the data statistically significant, but considering the results of both tests, I would not draw any strong conclusions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chi-square test of pregnancy length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PregLengthTest(thinkstats2.HypothesisTest):\n",
    "\n",
    "    def MakeModel(self):\n",
    "        firsts, others = self.data\n",
    "        self.n = len(firsts)\n",
    "        self.pool = np.hstack((firsts, others))\n",
    "\n",
    "        pmf = thinkstats2.Pmf(self.pool)\n",
    "        self.values = range(35, 44)\n",
    "        self.expected_probs = np.array(pmf.Probs(self.values))\n",
    "\n",
    "    def RunModel(self):\n",
    "        np.random.shuffle(self.pool)\n",
    "        data = self.pool[:self.n], self.pool[self.n:]\n",
    "        return data\n",
    "    \n",
    "    def TestStatistic(self, data):\n",
    "        firsts, others = data\n",
    "        stat = self.ChiSquared(firsts) + self.ChiSquared(others)\n",
    "        return stat\n",
    "\n",
    "    def ChiSquared(self, lengths):\n",
    "        hist = thinkstats2.Hist(lengths)\n",
    "        observed = np.array(hist.Freqs(self.values))\n",
    "        expected = self.expected_probs * len(lengths)\n",
    "        stat = sum((observed - expected)**2 / expected)\n",
    "        return stat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we specifically test the deviations of first babies and others from the expected number of births in each week of pregnancy, the results are statistically significant with a very small p-value.  But at this point we have run so many tests, we should not be surprised to find at least one that seems significant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p-value = 0.0\n",
      "actual = 101.50141482893264\n",
      "ts max = 29.85063260096127\n"
     ]
    }
   ],
   "source": [
    "data = firsts.prglngth.values, others.prglngth.values\n",
    "ht = PregLengthTest(data)\n",
    "p_value = ht.PValue()\n",
    "print('p-value =', p_value)\n",
    "print('actual =', ht.actual)\n",
    "print('ts max =', ht.MaxTestStat())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Power\n",
    "\n",
    "Here's the function that estimates the probability of a non-significant p-value even is there really is a difference between the groups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def FalseNegRate(data, num_runs=1000):\n",
    "    \"\"\"Computes the chance of a false negative based on resampling.\n",
    "\n",
    "    data: pair of sequences\n",
    "    num_runs: how many experiments to simulate\n",
    "\n",
    "    returns: float false negative rate\n",
    "    \"\"\"\n",
    "    group1, group2 = data\n",
    "    count = 0\n",
    "\n",
    "    for i in range(num_runs):\n",
    "        sample1 = thinkstats2.Resample(group1)\n",
    "        sample2 = thinkstats2.Resample(group2)\n",
    "        ht = DiffMeansPermute((sample1, sample2))\n",
    "        p_value = ht.PValue(iters=101)\n",
    "        if p_value > 0.05:\n",
    "            count += 1\n",
    "\n",
    "    return count / num_runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.709"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neg_rate = FalseNegRate(data)\n",
    "neg_rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example, the false negative rate is 70%, which means that the power of the test (probability of statistical significance if the actual difference is 0.078 weeks) is only 30%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise:** As sample size increases, the power of a hypothesis test increases, which means it is more likely to be positive if the effect is real. Conversely, as sample size decreases, the test is less likely to be positive even if the effect is real.\n",
    "\n",
    "To investigate this behavior, run the tests in this chapter with different subsets of the NSFG data. You can use `thinkstats2.SampleRows` to select a random subset of the rows in a DataFrame.\n",
    "\n",
    "What happens to the p-values of these tests as sample size decreases? What is the smallest sample size that yields a positive test?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Josh\\AppData\\Local\\Temp\\ipykernel_15068\\3737612681.py:14: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  firsts = sample[live.birthord == 1]\n",
      "C:\\Users\\Josh\\AppData\\Local\\Temp\\ipykernel_15068\\3737612681.py:15: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  others = sample[live.birthord != 1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The results for round #1 of testing are:\n",
      "P1: 0.161, P2: 0.0, P3: 0.0, P4: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Josh\\AppData\\Local\\Temp\\ipykernel_15068\\3737612681.py:14: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  firsts = sample[live.birthord == 1]\n",
      "C:\\Users\\Josh\\AppData\\Local\\Temp\\ipykernel_15068\\3737612681.py:15: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  others = sample[live.birthord != 1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The results for round #1 of testing are:\n",
      "P1: 0.121, P2: 0.002, P3: 0.0, P4: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Josh\\AppData\\Local\\Temp\\ipykernel_15068\\3737612681.py:14: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  firsts = sample[live.birthord == 1]\n",
      "C:\\Users\\Josh\\AppData\\Local\\Temp\\ipykernel_15068\\3737612681.py:15: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  others = sample[live.birthord != 1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The results for round #1 of testing are:\n",
      "P1: 0.853, P2: 0.093, P3: 0.0, P4: 0.002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Josh\\AppData\\Local\\Temp\\ipykernel_15068\\3737612681.py:14: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  firsts = sample[live.birthord == 1]\n",
      "C:\\Users\\Josh\\AppData\\Local\\Temp\\ipykernel_15068\\3737612681.py:15: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  others = sample[live.birthord != 1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The results for round #1 of testing are:\n",
      "P1: 0.834, P2: 0.047, P3: 0.0, P4: 0.0\n"
     ]
    }
   ],
   "source": [
    "# Pull in the data to use from NSFG\n",
    "live, firsts, others = first.MakeFrames()\n",
    "\n",
    "# Set the length of the variable.\n",
    "lengthLive = len(live)\n",
    "\n",
    "# Look through the test samples to test the correlations\n",
    "for _ in range(4):\n",
    "\n",
    "    # Pull the sample from the rows.\n",
    "    sample = thinkstats2.SampleRows(live, lengthLive)\n",
    "\n",
    "    # use the sample to set up the new dataset\n",
    "    firsts = sample[live.birthord == 1]\n",
    "    others = sample[live.birthord != 1]\n",
    "\n",
    "    data = firsts.prglngth.values, others.prglngth.values\n",
    "\n",
    "    # Add in the hypothesis test and the pvalue\n",
    "    ht = DiffMeansPermute(data)\n",
    "    pvalue1 = ht.PValue(iters=1000) # use 1000 iterations\n",
    "\n",
    "    # Compare the pregnancy lengths \n",
    "    pregLengthData = firsts.totalwgt_lb.dropna().values, others.totalwgt_lb.dropna().values\n",
    "    ht = DiffMeansPermute(pregLengthData)\n",
    "    pvalue2 = ht.PValue(iters=1000)\n",
    "\n",
    "    # Test for the correlation between the subsets.\n",
    "    cleaned = live.dropna(subset=['agepreg', 'totalwgt_lb'])\n",
    "    cleanedData = cleaned.agepreg.values, cleaned.totalwgt_lb.values\n",
    "    ht = CorrelationPermute(cleanedData)\n",
    "    pvalue3 = ht.PValue(iters=1000)\n",
    "\n",
    "    # Compare the pregnancy lengths using the chi-squared method\n",
    "    # Use the same data variable that hasn't changed.\n",
    "    ht = PregLengthTest(data)\n",
    "    pvalue4 = ht.PValue(iters=1000)\n",
    "\n",
    "    # Print the results\n",
    "    count = 1\n",
    "    print(f'The results for round #{count} of testing are:')\n",
    "    print(f'P1: {pvalue1}, P2: {pvalue2}, P3: {pvalue3}, P4: {pvalue4}')\n",
    "\n",
    "    # Divide the results of n to simulate decreasing the size.\n",
    "    lengthLive //= 2\n",
    "    count += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conclusion...\n",
    "'''\n",
    "What happens to the p-values of these tests as sample size decreases? What is the smallest sample size that yields a positive test?\n",
    "\n",
    "As the sample size decreases, the p-values increase away from a value that is considered statistically significant (0.05).  However,\n",
    "for the first tests performed (pvalue1), we can see a much larger change in value as the sample size diminishes which doesn't \n",
    "necessarily go up/down consistently.  The smallest sample size that yields a positive test would be the final one used in this test\n",
    "since the behavior of the values still trends low for values pvalue3 and pvalue4.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "9650cb4e16cdd4a8e8e2d128bf38d875813998db22a3c986335f89e0cb4d7bb2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
