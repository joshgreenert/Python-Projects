{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b5fca2ca",
   "metadata": {},
   "source": [
    "# Data Preparation Week 9 and 10\n",
    "## Joshua Greenert\n",
    "## DSC540-T301 Data Preparation\n",
    "## 10/28/2022"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aeab84e",
   "metadata": {},
   "source": [
    "## Data Wrangling with Python Activity 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "d017a741",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the required libraries.\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import ssl\n",
    "import urllib.request, urllib.parse, urllib.error\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "f7893421",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the SSL cert.\n",
    "ctx = ssl.create_default_context()\n",
    "ctx.check_hostname = False\n",
    "ctx.verify_mode = ssl.CERT_NONE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "30ca1882",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the HTML from the url\n",
    "top100url = 'https://www.gutenberg.org/browse/scores/top'\n",
    "response = requests.get(top100url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "99f2364a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success!\n"
     ]
    }
   ],
   "source": [
    "# Write a small function to check the status of the web request.\n",
    "def check_status(response):\n",
    "    if response.status_code == 200:\n",
    "        print(\"Success!\")\n",
    "    else:\n",
    "        print(\"Failed!\")\n",
    "\n",
    "check_status(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "1ff5b387",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decode the response and pass this on to Beautiful Soup for HTML parsing.\n",
    "content = response.content.decode(response.encoding)\n",
    "soup = BeautifulSoup(content, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "fbd5b9e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/',\n",
       " '/about/',\n",
       " '/about/',\n",
       " '/policy/collection_development.html',\n",
       " '/about/contact_information.html',\n",
       " '/about/background/',\n",
       " '/policy/permission.html',\n",
       " '/policy/privacy_policy.html',\n",
       " '/policy/terms_of_use.html',\n",
       " '/ebooks/',\n",
       " '/ebooks/',\n",
       " '/ebooks/bookshelf/',\n",
       " '/browse/scores/top',\n",
       " '/ebooks/offline_catalogs.html',\n",
       " '/help/',\n",
       " '/help/',\n",
       " '/help/copyright.html',\n",
       " '/help/errata.html',\n",
       " '/help/file_formats.html',\n",
       " '/help/faq.html',\n",
       " '/policy/',\n",
       " '/help/public_domain_ebook_submission.html',\n",
       " '/help/submitting_your_own_work.html',\n",
       " '/help/mobile.html',\n",
       " '/attic/',\n",
       " '/donate/',\n",
       " '/donate/',\n",
       " '#books-last1',\n",
       " '#authors-last1',\n",
       " '#books-last7']"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find all the href tags and store them in the list of links.  Print the first 30 elements.\n",
    "href_links = []\n",
    "\n",
    "# Loop through the soup to get the links.\n",
    "for i in soup.find_all('a'):\n",
    "    href_links.append(i.get('href'))\n",
    "    \n",
    "href_links[:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "f65a7a79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use a regular expression to find the numeric digits in the links.  These are the file number for top 100 ebooks.\n",
    "books = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "861d7c2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1,\n",
       " 1,\n",
       " 7,\n",
       " 7,\n",
       " 30,\n",
       " 30,\n",
       " 2641,\n",
       " 145,\n",
       " 37106,\n",
       " 16389,\n",
       " 67979,\n",
       " 6761,\n",
       " 2701,\n",
       " 100,\n",
       " 394,\n",
       " 2160,\n",
       " 4085,\n",
       " 6593,\n",
       " 5197,\n",
       " 1259,\n",
       " 84,\n",
       " 1342,\n",
       " 25344,\n",
       " 41,\n",
       " 345,\n",
       " 20228,\n",
       " 98,\n",
       " 11,\n",
       " 1661,\n",
       " 69252,\n",
       " 2542,\n",
       " 1952,\n",
       " 174,\n",
       " 64317,\n",
       " 46,\n",
       " 69250,\n",
       " 76,\n",
       " 43,\n",
       " 1080,\n",
       " 69249,\n",
       " 74,\n",
       " 4300,\n",
       " 1400,\n",
       " 2591,\n",
       " 1260,\n",
       " 2554,\n",
       " 1184,\n",
       " 69251,\n",
       " 2600,\n",
       " 23,\n",
       " 43453,\n",
       " 6130,\n",
       " 5200,\n",
       " 844,\n",
       " 1232,\n",
       " 408,\n",
       " 730,\n",
       " 205,\n",
       " 120,\n",
       " 69246,\n",
       " 45,\n",
       " 3207,\n",
       " 514,\n",
       " 996,\n",
       " 42108,\n",
       " 69254,\n",
       " 69253,\n",
       " 1727,\n",
       " 219,\n",
       " 779,\n",
       " 33283,\n",
       " 16328,\n",
       " 28054,\n",
       " 58585,\n",
       " 2148,\n",
       " 158,\n",
       " 140,\n",
       " 135,\n",
       " 829,\n",
       " 55,\n",
       " 768,\n",
       " 3600,\n",
       " 30254,\n",
       " 16,\n",
       " 203,\n",
       " 10,\n",
       " 766,\n",
       " 1497,\n",
       " 5740,\n",
       " 2852,\n",
       " 1399,\n",
       " 3206]"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize the empty list to hold the file numbers and use regex to find the numeric digits in the link href string.\n",
    "# Use the findall method.\n",
    "for i in range(19, 119):\n",
    "    \n",
    "    # Get the link and strip it.\n",
    "    book = href_links[i]\n",
    "    book = book.strip()\n",
    "    \n",
    "    # Use regular expression to find digits.\n",
    "    count = re.findall('[0-9]+', book)\n",
    "    \n",
    "    # If there are digits in the book, add it to the list.\n",
    "    if(len(count) == 1):\n",
    "        books.append(int(count[0]))\n",
    "        \n",
    "books"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "fe45107f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "Top 100 | Project Gutenberg\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Menu▾\n",
      "\n",
      "\n",
      "\n",
      "About\n",
      "          ▾\n",
      "\n",
      "▾\n",
      "\n",
      "\n",
      "About Project Gutenberg\n",
      "Collection Development\n",
      "Contact Us\n",
      "History & Philosophy\n",
      "Permissions & License\n",
      "Privacy Policy\n",
      "Terms of Use\n",
      "\n",
      "\n",
      "\n",
      "Search and Browse\n",
      "      \t  ▾\n",
      "\n",
      "▾\n",
      "\n",
      "\n",
      "Book Search\n",
      "Bookshelves\n",
      "Frequently Downloaded\n",
      "Offline Catalogs\n",
      "\n",
      "\n",
      "\n",
      "Help\n",
      "          ▾\n",
      "\n",
      "▾\n",
      "\n",
      "\n",
      "All help topics →\n",
      "Copyright Procedures\n",
      "Errata, Fixes and Bug Reports\n",
      "File Formats\n",
      "Frequently Asked Questions\n",
      "Policies →\n",
      "Public Domain eBook Submission\n",
      "Submitting Your Own Work\n",
      "Tablets, Phones and eReaders\n",
      "The Attic →\n",
      "\n",
      "\n",
      "Donate\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Donation\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Frequently Viewed or Downloaded\n",
      "These listings are based on the number of times each eBook gets downloaded.\n",
      "      Multiple downloads from the same Internet address on the same day count as one download, and addresses that download more than 100 eBooks in a day are considered robots and are not counted.\n",
      "\n",
      "Downloaded Books\n",
      "2022-10-28248230\n",
      "last 7 days1786490\n",
      "last 30 days7065183\n",
      "\n",
      "\n",
      "\n",
      "Top 100 EBooks yesterday\n",
      "Top 100 Authors yesterday\n",
      "Top 100 EBooks last 7 days\n",
      "Top 100 Authors last 7 days\n",
      "Top 100 EBooks last 30 days\n",
      "Top 100 Authors last 30 days\n",
      "\n",
      "\n",
      "Top 100 EBooks yesterday\n",
      "\n",
      "A Room with a View by E. M.  Forster (6364)\n",
      "Middlemarch by George Eliot (5950)\n",
      "Little Women; Or, Meg, Jo, Beth, and Amy by Louisa May Alcott (5425)\n",
      "The Enchanted April by Elizabeth Von Arnim (5392)\n",
      "The Blue Castle: a novel by L. M.  Montgomery (5191)\n",
      "The Adventures of Ferdinand Count Fathom — Complete by T.  Smollett (5142)\n",
      "Moby Dick; Or, The Whale by Herman Melville (5129)\n",
      "The Complete Works of William Shakespeare by William Shakespeare (5106)\n",
      "Cranford by Elizabeth Cleghorn Gaskell (5034)\n",
      "The Expedition of Humphry Clinker by T.  Smollett (4973)\n",
      "The Adventures of Roderick Random by T.  Smollett (4924)\n",
      "History of Tom Jones, a Foundling by Henry Fielding (4665)\n",
      "My Life — Volume 1 by Richard Wagner (4511)\n",
      "Twenty Years After by Alexandre Dumas (4481)\n",
      "Frankenstein; Or, The Modern Prometheus by Mary Wollstonecraft Shelley (24\n"
     ]
    }
   ],
   "source": [
    "# What does the soup object's text look like?  Use the .text method and print only the first 2,000 characters \n",
    "# (not the whole string)\n",
    "print(soup.text[:2000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "67279bb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search in the extracted text from the soup object to find the names of the top 100 ebooks.\n",
    "book_titles = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "cf1d6950",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a starting index.  It should point at the text top 100 ebooks yesterday.  Use the splitlines method of soup.text\n",
    "# It splits the lines of text of the soup object.\n",
    "index = soup.text.splitlines().index('Top 100 EBooks yesterday')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "857ef4af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop 1 - 100 to add the strings of the next 100 lines to this temporary list.\n",
    "# Hint: use the splitlines method.\n",
    "for i in range(100):\n",
    "    book_titles.append(soup.text.splitlines()[index + 10 + i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "a0c58eda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['A Room with a View by E',\n",
       " 'Middlemarch by George Eliot ',\n",
       " 'Little Women',\n",
       " 'The Enchanted April by Elizabeth Von Arnim ',\n",
       " 'The Blue Castle',\n",
       " 'The Adventures of Ferdinand Count Fathom ',\n",
       " 'Moby Dick',\n",
       " 'The Complete Works of William Shakespeare by William Shakespeare ',\n",
       " 'Cranford by Elizabeth Cleghorn Gaskell ',\n",
       " 'The Expedition of Humphry Clinker by T',\n",
       " 'The Adventures of Roderick Random by T',\n",
       " 'History of Tom Jones',\n",
       " 'My Life ',\n",
       " 'Twenty Years After by Alexandre Dumas ',\n",
       " 'Frankenstein',\n",
       " 'Pride and Prejudice by Jane Austen ',\n",
       " 'The Scarlet Letter by Nathaniel Hawthorne ',\n",
       " 'The Legend of Sleepy Hollow by Washington Irving ',\n",
       " 'Dracula by Bram Stoker ',\n",
       " 'Noli Me Tangere by Jos',\n",
       " 'A Tale of Two Cities by Charles Dickens ',\n",
       " 'Alice',\n",
       " 'The Adventures of Sherlock Holmes by Arthur Conan Doyle ',\n",
       " 'White spot by Murray Leinster ',\n",
       " 'A Doll',\n",
       " 'The Yellow Wallpaper by Charlotte Perkins Gilman ',\n",
       " 'The Picture of Dorian Gray by Oscar Wilde ',\n",
       " 'The Great Gatsby by F',\n",
       " 'A Christmas Carol in Prose',\n",
       " 'The power of sympathy',\n",
       " 'Adventures of Huckleberry Finn by Mark Twain ',\n",
       " 'The Strange Case of Dr',\n",
       " 'A Modest Proposal by Jonathan Swift ',\n",
       " 'Sketches of Southern life by Frances E',\n",
       " 'The Adventures of Tom Sawyer',\n",
       " 'Ulysses by James Joyce ',\n",
       " 'Great Expectations by Charles Dickens ',\n",
       " 'Grimms',\n",
       " 'Jane Eyre',\n",
       " 'Crime and Punishment by Fyodor Dostoyevsky ',\n",
       " 'The Count of Monte Cristo',\n",
       " 'Stories for children',\n",
       " 'War and Peace by graf Leo Tolstoy ',\n",
       " 'Narrative of the Life of Frederick Douglass',\n",
       " 'A Pickle for the Knowing Ones by Timothy Dexter ',\n",
       " 'The Iliad by Homer ',\n",
       " 'Metamorphosis by Franz Kafka ',\n",
       " 'The Importance of Being Earnest',\n",
       " 'The Prince by Niccol',\n",
       " 'The Souls of Black Folk by W',\n",
       " 'Oliver Twist by Charles Dickens ',\n",
       " 'Walden',\n",
       " 'Treasure Island by Robert Louis Stevenson ',\n",
       " '',\n",
       " 'Anne of Green Gables by L',\n",
       " 'Leviathan by Thomas Hobbes ',\n",
       " 'Little Women by Louisa May Alcott ',\n",
       " 'Don Quixote by Miguel de Cervantes Saavedra ',\n",
       " 'The Slang Dictionary',\n",
       " 'The vortex blaster makes war by E',\n",
       " 'Signalling through space without wires by Oliver J',\n",
       " 'The Odyssey by Homer ',\n",
       " 'Heart of Darkness by Joseph Conrad ',\n",
       " 'The Tragical History of Doctor Faustus by Christopher Marlowe ',\n",
       " 'Calculus Made Easy by Silvanus P',\n",
       " 'Beowulf',\n",
       " 'The Brothers Karamazov by Fyodor Dostoyevsky ',\n",
       " 'The Prophet by Kahlil Gibran ',\n",
       " 'The Works of Edgar Allan Poe ',\n",
       " 'Emma by Jane Austen ',\n",
       " 'The Jungle by Upton Sinclair ',\n",
       " 'Les Mis',\n",
       " 'Gulliver',\n",
       " 'The Wonderful Wizard of Oz by L',\n",
       " 'Wuthering Heights by Emily Bront',\n",
       " 'Essays of Michel de Montaigne ',\n",
       " 'The Romance of Lust',\n",
       " 'Peter Pan by J',\n",
       " 'Uncle Tom',\n",
       " 'The King James Version of the Bible ',\n",
       " 'David Copperfield by Charles Dickens ',\n",
       " 'The Republic by Plato ',\n",
       " 'Tractatus Logico',\n",
       " 'The Hound of the Baskervilles by Arthur Conan Doyle ',\n",
       " 'Anna Karenina by graf Leo Tolstoy ',\n",
       " 'Moby Multiple Language Lists of Common Words by Grady Ward ',\n",
       " 'Hard Times by Charles Dickens ',\n",
       " 'Anthem by Ayn Rand ',\n",
       " 'The Jungle Book by Rudyard Kipling ',\n",
       " 'Second Treatise of Government by John Locke ',\n",
       " 'Dubliners by James Joyce ',\n",
       " 'A Study in Scarlet by Arthur Conan Doyle ',\n",
       " 'Autobiography of Benjamin Franklin by Benjamin Franklin ',\n",
       " 'Stories from Tagore by Rabindranath Tagore ',\n",
       " 'Winnie',\n",
       " 'The Call of the Wild by Jack London ',\n",
       " 'Thus Spake Zarathustra',\n",
       " 'Frankenstein',\n",
       " 'Atlanta offering',\n",
       " 'The King in Yellow by Robert W']"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use a regular expression to extract only text from the name strings and append it to an empty list.\n",
    "# Use match and span to find the indcies and use them.\n",
    "top_100_list = []\n",
    "\n",
    "# Loop through the objects collected and strip the book titles using regex.\n",
    "for i in range(100):\n",
    "    index1, index2 = re.match('^[a-zA-Z ]*', book_titles[i]).span()\n",
    "    top_100_list.append(book_titles[i][index1:index2])\n",
    "    \n",
    "top_100_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa97c3d6",
   "metadata": {},
   "source": [
    "## Data Wrangling with Python Activity 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "8d93f0a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the required libraries.\n",
    "import json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "e4ca4fe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the secret API key using json.loads.\n",
    "# https://www.omdbapi.com/?t=titanic&apikey=apikey\n",
    "with open('APIkey.json') as f:\n",
    "    keys = json.load(f)\n",
    "    omdbapi = keys['OMDBapi']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "fb2efb00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign the OMDB portal (http://www.omdbapi.com/?) as a string to a variable.\n",
    "websiteurl = 'http://www.omdbapi.com/?'\n",
    "apikey = '&apikey=' + omdbapi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "4b3914cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write a utility function called print_json to print the movie data from a json file (from the portal)\n",
    "def print_json(json_data):\n",
    "    list_keys=['Title', 'Year', 'Rated', 'Released', 'Runtime', 'Genre', 'Director', 'Writer', \n",
    "               'Actors', 'Plot', 'Language', 'Country', 'Awards', 'Ratings', \n",
    "               'Metascore', 'imdbRating', 'imdbVotes', 'imdbID']\n",
    "    \n",
    "    # loop through each key to get the value and print it for the user.\n",
    "    for j in list_keys:\n",
    "        if j in json_data.keys():\n",
    "            print(f\"{j}: {json_data[j]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "1074bf67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write a utility function to download a poster of the movie based on the information from the json dataset and save it\n",
    "# in your local folder.  Use the os module.  The poster data is stored in the json key poster.  Use the python command\n",
    "# to open a file and write the poster data.  Close the file after you're done (save as image file)\n",
    "def save_poster(json_data):\n",
    "    import os \n",
    "    \n",
    "    # Get the poster url and the title of the movie to save.\n",
    "    title = str(json_data['Title']) \n",
    "    poster_url = json_data['Poster']\n",
    "    \n",
    "    # Use the poster url to get the file type (jpeg, jpg, etc.)\n",
    "    poster_type = poster_url.split('.')[-1]\n",
    "    \n",
    "    # Save the data for the image.\n",
    "    poster_data = urllib.request.urlopen(poster_url).read()\n",
    "    \n",
    "    # Set the save location.\n",
    "    savelocation = os.getcwd() + '\\\\' + 'Posters' + '\\\\'\n",
    "    \n",
    "    # If the directory doesn't exist, make it.\n",
    "    if not os.path.isdir(savelocation):\n",
    "        os.mkdir(savelocation)\n",
    "        \n",
    "    # Create the file and save the poster data to it.\n",
    "    filename = savelocation + title + '.' + poster_type\n",
    "    \n",
    "    file = open(filename, 'wb')\n",
    "    file.write(poster_data)\n",
    "    file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "93a07cda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write a utility function called search_movie to search for a movie by its name, print the downloaded json data, and save\n",
    "# the movie poster in the local folder.  Use a try-except loop for this.  Use the previously created serviceurl and apikey\n",
    "# variables.  You have to pass on a dictionary with a key, t, and the movie name as the corresponding value to the \n",
    "# urlencode() function and then add the serviceurl and apikey to the output of the function to construct the full url.  This\n",
    "# url will be used to access the data.  The json data has a key called response.  If it is true, that means the read was\n",
    "# successful.  Check this before processing the data.  If it's not successful, print the json key error, which will contain\n",
    "# the appropriate error message returned by the movie database.\n",
    "def search_movie(title):\n",
    "    try:\n",
    "        # Set up the url for the request.\n",
    "        url = websiteurl + urllib.parse.urlencode({'t': str(title)}) + apikey\n",
    "        print(f'URL being retrieved: {url}')\n",
    "        \n",
    "        # Request the data and set it into a json object.\n",
    "        data_request = urllib.request.urlopen(url)\n",
    "        data = data_request.read()\n",
    "        json_data = json.loads(data)\n",
    "\n",
    "        # Check if the response is true or false.\n",
    "        if json_data['Response'] == 'True':\n",
    "            print_json(json_data)\n",
    "            \n",
    "            # if the json returns with the poster data, save it.\n",
    "            if json_data['Poster'] != 'N/A':\n",
    "                save_poster(json_data)\n",
    "        else:\n",
    "            print(f\"ERROR: {json_data['Error']}\")\n",
    "        \n",
    "    except urllib.error.URLError as exception:\n",
    "        print(f\"ERROR: {exception.reason}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "cd37ac54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "URL being retrieved: http://www.omdbapi.com/?t=Titanic&apikey=8200ded3\n",
      "True\n",
      "Title: Titanic\n",
      "Year: 1997\n",
      "Rated: PG-13\n",
      "Released: 19 Dec 1997\n",
      "Runtime: 194 min\n",
      "Genre: Drama, Romance\n",
      "Director: James Cameron\n",
      "Writer: James Cameron\n",
      "Actors: Leonardo DiCaprio, Kate Winslet, Billy Zane\n",
      "Plot: A seventeen-year-old aristocrat falls in love with a kind but poor artist aboard the luxurious, ill-fated R.M.S. Titanic.\n",
      "Language: English, Swedish, Italian, French\n",
      "Country: United States, Mexico\n",
      "Awards: Won 11 Oscars. 125 wins & 83 nominations total\n",
      "Ratings: [{'Source': 'Internet Movie Database', 'Value': '7.9/10'}, {'Source': 'Rotten Tomatoes', 'Value': '87%'}, {'Source': 'Metacritic', 'Value': '75/100'}]\n",
      "Metascore: 75\n",
      "imdbRating: 7.9\n",
      "imdbVotes: 1,159,706\n",
      "imdbID: tt0120338\n"
     ]
    }
   ],
   "source": [
    "# Test the search_movie function by entering Titanic.\n",
    "search_movie(\"Titanic\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "52cf231c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "URL being retrieved: http://www.omdbapi.com/?t=Random_error&apikey=8200ded3\n",
      "ERROR: Movie not found!\n"
     ]
    }
   ],
   "source": [
    "# Test the search_movie function by entering \"Random_error\"\n",
    "search_movie(\"Random_error\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42ff8497",
   "metadata": {},
   "source": [
    "## Connect to Twitter Sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "a0157095",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Author ID: 1533105519447404544\n",
      "Text: RT @Sheraj99: 7 Steps #MachineLearning #DataScience #SQL #Cybersecurity #BigData #Analytics #AI #IIoT #Python #RStats #TensorFlow #JavaScri…\n",
      "\n",
      "Author ID: 30467611\n",
      "Text: RT @KanezaDiane: About #MachineLearning ? #DataScience #Python #Linux #CyberSecurity #SQL #BigData #Analytics #AI #IoT #PyTorch #RStats #Te…\n",
      "\n",
      "Author ID: 1257170815881228295\n",
      "Text: RT @gp_pulipaka: 12 Machine Learning Books You Should Read in 2023. #BigData #Analytics #DataScience #IoT #IIoT #Python #RStats #TensorFlow…\n",
      "\n",
      "Author ID: 1533209625176248326\n",
      "Text: RT @Sheraj99: 7 Steps #MachineLearning #DataScience #SQL #Cybersecurity #BigData #Analytics #AI #IIoT #Python #RStats #TensorFlow #JavaScri…\n",
      "\n",
      "Author ID: 1102867005126905856\n",
      "Text: RT @Sheraj99: 7 Steps #MachineLearning #DataScience #SQL #Cybersecurity #BigData #Analytics #AI #IIoT #Python #RStats #TensorFlow #JavaScri…\n",
      "\n",
      "Author ID: 1102867005126905856\n",
      "Text: RT @gp_pulipaka: 12 Machine Learning Books You Should Read in 2023. #BigData #Analytics #DataScience #IoT #IIoT #Python #RStats #TensorFlow…\n",
      "\n",
      "Author ID: 1409076550675357699\n",
      "Text: RT @paulknulst: Good evening! Welcome to Day 53 of #100DaysOfJavascript! \n",
      "\n",
      "I will show a #javascript snippet to swap variables very easily!…\n",
      "\n",
      "Author ID: 1533105519447404544\n",
      "Text: RT @OnlineAssignm19: Pay us to handle your:\n",
      "English\n",
      "#essaypay\n",
      "Math\n",
      "Chem\n",
      "#assignment due\n",
      "Economics\n",
      "#javascript\n",
      "Algebra\n",
      "homework\n",
      "#Psychology…\n",
      "\n",
      "Author ID: 1276058041389953024\n",
      "Text: RT @paulknulst: Good evening! Welcome to Day 53 of #100DaysOfJavascript! \n",
      "\n",
      "I will show a #javascript snippet to swap variables very easily!…\n",
      "\n",
      "Author ID: 1551060443040325632\n",
      "Text: RT @paulknulst: Good evening! Welcome to Day 53 of #100DaysOfJavascript! \n",
      "\n",
      "I will show a #javascript snippet to swap variables very easily!…\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import os\n",
    "import json\n",
    "\n",
    "# Set up the api connection\n",
    "bearer_token = \"AAAAAAAAAAAAAAAAAAAAAH3HigEAAAAApWixubJom%2BYZEQQLNmjlPP7mMXE%3Drfuw5ezx3wgBGUeqHlYRXv3LLlVGb5fKOPhll0BdG3iJOTrGm0\"\n",
    "\n",
    "# Set up url and query parameters.\n",
    "search_url = \"https://api.twitter.com/2/tweets/search/recent\"\n",
    "query_params = {'query': '#bellevue OR #datascience','tweet.fields': 'author_id'}\n",
    "\n",
    "# Set the headers for the bearer token.\n",
    "def bearer_oauth(r):\n",
    "    r.headers[\"Authorization\"] = f\"Bearer {bearer_token}\"\n",
    "    r.headers[\"User-Agent\"] = \"v2RecentSearchPython\"\n",
    "    return r\n",
    "\n",
    "# Connect to the search endpoint and to return data.\n",
    "def connect_to_endpoint(url, params):\n",
    "    response = requests.get(url, auth=bearer_oauth, params=params)\n",
    "    if response.status_code != 200:\n",
    "        raise Exception(response.status_code, response.text)\n",
    "    return response.json()\n",
    "\n",
    "# Get the response.\n",
    "json_response = connect_to_endpoint(search_url, query_params)\n",
    "json_data = json.dumps(json_response)\n",
    "\n",
    "# Parse the response and print the author id and text.\n",
    "for val in json_response[\"data\"]:\n",
    "    print(f'\\nAuthor ID: {val[\"author_id\"]}\\nText: {val[\"text\"].strip()}')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f3e23ec",
   "metadata": {},
   "source": [
    "## Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6faf7c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using one of the datasets provided in Weeks 7 & 8, or a dataset of your own, choose 3 of the following visualizations \n",
    "# to complete. You must submit via PDF along with your code. You are free to use Matplotlib, Seaborn or another package \n",
    "# if you prefer. (line, bar, scatter, histogram, density plot, pie chart)\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create the dataframe.\n",
    "df_candy = pd.read_csv('candyhierarchy2017.csv',  encoding = \"ISO-8859-1\")\n",
    "\n",
    "# Replace values with mode for all categorical columns.\n",
    "categorical_columns = df_candy.select_dtypes( include ='object').columns\n",
    "df_candy[categorical_columns] = df_candy[categorical_columns].apply(lambda x: x.fillna(x.value_counts().index[0]))\n",
    "\n",
    "columns_to_drop = ['Q12: MEDIA [Daily Dish]','Q12: MEDIA [ESPN]', 'Q12: MEDIA [Yahoo]' ]\n",
    "df_candy = df_candy.drop(columns_to_drop, axis=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
