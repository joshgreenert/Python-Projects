{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5559e763",
   "metadata": {},
   "source": [
    "# Predictive Analytics: Milestone 4\n",
    "#### Joshua Greenert, Gabriel Avinaz, and Mithil Patel\n",
    "#### DSC630-T301 Predictive Analytics\n",
    "#### 2/10/2023"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98036a86",
   "metadata": {},
   "source": [
    "### Milestone 2: Data Selection and Proposal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "665da0ec",
   "metadata": {},
   "source": [
    "#### Introduction "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b618886",
   "metadata": {},
   "source": [
    "Since antiquity, games have been an integral aspect of human society – especially for cultural development and social interaction. With the advancement of human civilization, the way games are being played has drastically changed over the eons as modern games are primarily played electronically (video games). With over 3 billion players worldwide and approximately 200 billion dollars in revenue, the video gaming industry is constantly looking to attract new customers and boost playtime. As a result, we will implement a collaborative recommendation system to assist users in finding similar games that may interest them. By utilizing a collaborative filtering system, we can use historical review information to determine whether a product might interest one of our customers. We will experiment with two approaches to determine which application would be better for an e-commerce implementation.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d22cc008",
   "metadata": {},
   "source": [
    "#### What types of model(s) do you plan to use and why, and how do you intend to evaluate your results?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88e81c69",
   "metadata": {},
   "source": [
    "We will implement a collaborative recommendation system to assist users in finding similar games that may interest them. By utilizing a collaborative filtering system, we can use historical review information to determine whether a product might interest one of our customers. We will experiment with two approaches to determine which application would be better for an e-commerce implementation.  \n",
    "  \n",
    "Our first approach will implement memory-based collaborative filtering, which utilizes the collective review information of other users to find similar games. We’ll be implementing both item-item and user-item methods to determine which provides a better result for our users. These two methods offer predictions based on what similar users like and what users who like a particular game are likely to enjoy. We’ll use several distance measurement algorithms to determine which provides a more accurate recommendation such as: cosine similarity, Pearson Correlation, and K-nearest neighbors. The models created using these methods should perform fastest while providing acceptable accuracy.  For our model-based collaborative filtering, we will train a few machine learning (ML) algorithms to make recommendations and find similar games. Our project will focus on utilizing matrix factorization algorithms to make this determination but will be looking to implement a deep learning approach given the time. The process of applying different ML algorithms is fairly simple, so we’ll be looking to implement the most we can: SVD, PMF, and NMF, then compare our results with the memory-based results.  \n",
    "  \n",
    "  Our second approach to creating a recommendation system for our games library is by implementing a content-based filtering system utilizing natural language processing and available user reviews. This process will use a vectorized matrix of user reviews to find games that have been reviewed in a similar way. We can implement many of the techniques from our memory-based collaborative filtering process into this one and measure performance across each of our distance-measuring algorithms.  We can utilize a standard train-test methodology from many of the of the models we will be implementing while cross referencing our suggested games with user-rated games.  We also have user information in our data set as to whether they would make a recommendation for the game they are reviewing.  We can utilize this data in testing our results accuracy. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64a99f9c",
   "metadata": {},
   "source": [
    "#### What do you hope to learn?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8df01530",
   "metadata": {},
   "source": [
    "We hope to learn consumers’ interests and buying patterns which can help our company optimize revenue by focusing resources on developing games customers will more likely enjoy.  Additionally, we intend to learn appropriate methods to develop recommendation systems for alternative enterprises and future outsourcing.  Finally, while going through this process, we expect to learn data from our models that can be used for other points of interest for the company and our personal career development."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88112aa7",
   "metadata": {},
   "source": [
    "#### Are there any risks or ethical implications with your proposal?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97d11a17",
   "metadata": {},
   "source": [
    "Fortunately, all of the personal information of each individual review has been stripped from the data provided from the Steam API.  Instead of the actual user’s profile information, a review_id value is used instead.  However, the comments may contain personal or sensitive information which will be appropriately handled or removed to ensure the safety and security of all users.  Besides potential user-provided information, there are no additional risks or ethical concerns within this project.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "824151c1",
   "metadata": {},
   "source": [
    "#### What is your contingency plan?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebb6f68c",
   "metadata": {},
   "source": [
    "In the event that our findings aren’t conclusive, our dataset proves too massive to work with, or our data doesn’t express a proper recommendation system as intended, we have collected another dataset to use instead.  This database revolves around used cars posted to Craigslist and would have a similar strategy to our current proposal.  We would use the dataset to review models for recommendations for users based upon their interests and preferences.  From that information, we would predict cars that users would be interested in while also being local to their respective area based on the information from the dataset.  All parties have agreed that if our project doesn’t appear feasible by the end of week 3, we will be shifting gears to this alternative to salvage the time we have remaining."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76336410",
   "metadata": {},
   "source": [
    "#### Additional important information"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4b68d0a",
   "metadata": {},
   "source": [
    "As the project progresses, we plan to implement a deep learning algorithm if we are able to add it into the scope; at the moment, we anticipate our limited time will be a factor that prevents us from doing so.  With a deep learning algorithm, we would be able to enhance our accuracy and predict better recommendations for our users.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29b1d019",
   "metadata": {},
   "source": [
    "### Milestone 3: Preliminary Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e73aba99",
   "metadata": {},
   "source": [
    "#### Will I be able to answer the questions I want to answer with the data I have?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfe1bb9d",
   "metadata": {},
   "source": [
    "The data are proving to be far more time-consuming than initially expected.  Nevertheless, the data should be more than capable of providing a model of a working recommendation system that can suggest games to users based on their game preference.  Additionally, our team has utilized a supplemental dataset to create alternative options for our recommendations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67157167",
   "metadata": {},
   "source": [
    "#### What visualizations are especially useful for explaining my data?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bf1470d",
   "metadata": {},
   "source": [
    "Histogram plots were one of the most useful visualizations in evaluating our data.  It helped us determine that a large number of users that left reviews on the steam application would only leave a review for one game.  This has a significant effect on how we can treat the data going forward, especially with the collaborative filtering models we were going to attempt to implement.  Bar plots can be used to display our model’s outputs, showing ratios of similarity with each game.  Scatterplots were one of the more important visualizations in determining how to measure our aggregate review data for each game.  It helped us determine how the average score changed between positive reviews and those weighted for quality."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87e000f7",
   "metadata": {},
   "source": [
    "#### Do I need to adjust the data and/or driving questions?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "477e2e7c",
   "metadata": {},
   "source": [
    "Due to the size of our data selected, we have implemented a checkpoint inside of our file where a csv file is exported after a rigorous six-hour lemmatization.  This export can then be used to continue the process of creating the remainder of the model while utilizing the results of the previous steps.  While an adjustment to the process and data was a serious consideration, the checkpoint simplifies the approach and allows us to begin further development without the need to start from the beginning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dadb2493",
   "metadata": {},
   "source": [
    "#### Do I need to adjust my model/evaluation choices?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd742ba2",
   "metadata": {},
   "source": [
    "For the most part, our models and methodology appear to be functioning as intended.  Our intention is to use Term Frequency-Inverse Document Frequency (TFIDF) vectorized user reviews and game descriptions with cosine similarity as a metric to measure the closeness of each recommendation.  Additionally, we plan to have a collaborative filtering model utilizing K Nearest Neighbor (KNN), random forest, and XGBoost as classifiers based on the user’s review history.  The expectation is to utilize GridSearchCV to find the ideal model and parameters for this method.  Nothing at the moment appears to require a significant change, but we learned from our visualizations that we can gain a significant amount of efficiency by dropping users that have only contributed a single review from the collaborative dataset, and we will still have plenty of entries after the fact to split up data into training and test sets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe40fe0d",
   "metadata": {},
   "source": [
    "#### Are my original expectations still reasonable?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "186b62f8",
   "metadata": {},
   "source": [
    "Our initial expectations were to create a prediction model that could make recommendations based on the reviews from Steam users.  This expectation still shows promise as we’ve completed the majority of the modeling process.  However, the expectation to create a neural network with the dataset may prove challenging based on the size of the dataset, and how long the process took for lemmatization.  Alternatively, we’ve chosen to include an alternative dataset for an additional option on recommendation systems."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbe5b1fc",
   "metadata": {},
   "source": [
    "### Milestone 4: Finalizing Results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1d37786",
   "metadata": {},
   "source": [
    "#### Explain your process for preparing the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ede265de",
   "metadata": {},
   "source": [
    "Our initial dataset contained a massive amount of rows and comments from Steam users.  However, most of the reviews were in other languages.  First, we removed all of the other languages besides “english” to ensure we could use and understand the results of the model.  Next, we dropped columns that we estimated were insignificant to our process and made dummies for the remaining categorical variables.  We imported libraries for keyword sentiment analysis and proceeded to lemmatize the comments from each user to remove stop words and contractions; this process (in code) took over 6 hours!  Afterwards, we created a checkpoint to begin the final processes with our dataset by adding another dataset to use for cosine similarity.  Here are some of the steps performed in code:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d503d236",
   "metadata": {},
   "source": [
    "### DO NOT RUN: ONLY FOR VISUAL PURPOSES!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5159b276",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the language column, we can remove all other languages besides english.\n",
    "df_steam_reviews = df_steam_reviews[df_steam_reviews['language'] == 'english']\n",
    "\n",
    "# Drop the columns that we don't need.\n",
    "df_steam_reviews = df_steam_reviews.drop(['Unnamed: 0', 'review_id', 'language','author.num_games_owned', \n",
    "                                          'author.last_played' ], axis = 1)\n",
    "\n",
    "# Make dummies of the columns that can conform.\n",
    "df_reviews_dummies = pd.get_dummies(df_steam_reviews, columns=['recommended', 'steam_purchase', 'received_for_free',\n",
    "                                                              'written_during_early_access'])\n",
    "\n",
    "# Calling the process_sentence_lemmatize function through the apply method; skipped some steps to reduce file size.\n",
    "# This is the part that took 6 hours!\n",
    "df_reviews_dummies['prepped_review_lemm'] = df_reviews_dummies.review.apply(process_sentence_lemmatize)  \n",
    "\n",
    "# Calling the process_sentence_lemmatize function through the apply method.\n",
    "df_steam_games['prepped_description_lemm'] = df_steam_games['Short Description'].apply(process_sentence_lemmatize)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ed1b707",
   "metadata": {},
   "source": [
    "#### Build and evaluate at least one model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6d4ef829",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the required libaries.\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from scipy.sparse import csr_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "182eca6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pull in the dataframe.\n",
    "\n",
    "# Josh G\n",
    "# df_reviews_dummies = pd.read_csv('../../../../../Downloads/Prepped_test_out.csv', on_bad_lines=\"skip\", engine=\"python\")\n",
    "# df_reviews = pd.read_csv('../../../../../Downloads/steam_reviews.csv', low_memory=False)\n",
    "# df_steam_games = pd.read_csv('../../../../../Downloads/Prepped_games_out.csv')\n",
    "# df_steam_games = df_steam_games.set_index('App ID')\n",
    "\n",
    "# Gabe\n",
    "df_reviews_dummies = pd.read_csv('Prepped_test_out.csv')\n",
    "df_reviews = pd.read_csv('steam_reviews.csv')\n",
    "df_steam_games = pd.read_csv('Prepped_games_out.csv')\n",
    "df_steam_games = df_steam_games.set_index('App ID')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9989e545",
   "metadata": {},
   "source": [
    "As noted above, we brought in some new datasets to use for comparison on our models generated.  The goal was to create a model that was fairly consistent to compare against the lemmatized model we would use later on.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "80b5cef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge the two columns into one\n",
    "df_reviews_dummies[\"recommended\"] = df_reviews_dummies['recommended_False'] + df_reviews_dummies['recommended_True']\n",
    "\n",
    "# Set the user recommendation dataframes.\n",
    "user_rec_df_reviews = df_reviews[[\"app_id\",\"author.steamid\", \"recommended\"]].copy()\n",
    "user_rec_df_prepped = df_reviews_dummies[[\"app_id\",\"author.steamid\", \"recommended\"]].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ba95f3cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21747371 315 12406560\n",
      "9635437 315 5287718\n"
     ]
    }
   ],
   "source": [
    "# Set the values that will be used for the matrix dimensions.\n",
    "n_ratings_reviews = len(user_rec_df_reviews)\n",
    "n_games_reviews = len(user_rec_df_reviews['app_id'].unique())\n",
    "n_users_reviews = len(user_rec_df_reviews['author.steamid'].unique())\n",
    "\n",
    "n_ratings_prepped = len(user_rec_df_prepped)\n",
    "n_games_prepped = len(user_rec_df_prepped['app_id'].unique())\n",
    "n_users_prepped = len(user_rec_df_prepped['author.steamid'].unique())\n",
    "\n",
    "# Print the results to confirm they have values.\n",
    "print(n_ratings_reviews, n_games_reviews, n_users_reviews)\n",
    "print(n_ratings_prepped, n_games_prepped, n_users_prepped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "bf7d2f2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "# maps idices to users and game IDs\n",
    "user_map_reviews = dict(zip(np.unique(user_rec_df_reviews[\"author.steamid\"]), list(range(n_users_reviews))))\n",
    "game_map_reviews = dict(zip(np.unique(user_rec_df_reviews[\"app_id\"]), list(range(n_games_reviews))))\n",
    "\n",
    "# Confirm that the total reviews equal the n_games_reviews. Should be true, true.\n",
    "print(len(user_map_reviews) == n_users_reviews)\n",
    "print(len(game_map_reviews) == n_games_reviews)\n",
    "\n",
    "user_i_map_reviews = dict(zip(list(range(n_users_reviews)), np.unique(user_rec_df_reviews[\"author.steamid\"])))\n",
    "game_i_map_reviews = dict(zip(list(range(n_games_reviews)), np.unique(user_rec_df_reviews[\"app_id\"])))\n",
    "\n",
    "# Perform the same operations on the prepped items.\n",
    "user_map_prepped = dict(zip(np.unique(user_rec_df_prepped[\"author.steamid\"]), list(range(n_users_prepped))))\n",
    "game_map_prepped = dict(zip(np.unique(user_rec_df_prepped[\"app_id\"]), list(range(n_games_prepped))))\n",
    "\n",
    "# Confirm that the total reviews equal the n_games_reviews. Should be true, true.\n",
    "print(len(user_map_prepped) == n_users_prepped)\n",
    "print(len(game_map_prepped) == n_games_prepped)\n",
    "\n",
    "user_i_map_prepped = dict(zip(list(range(n_users_prepped)), np.unique(user_rec_df_prepped[\"author.steamid\"])))\n",
    "game_i_map_prepped = dict(zip(list(range(n_games_prepped)), np.unique(user_rec_df_prepped[\"app_id\"])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b3043eae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating indices for csr_matrix\n",
    "user_index_reviews = [user_map_reviews[i] for i in user_rec_df_reviews['author.steamid']]\n",
    "game_index_reviews = [game_map_reviews[i] for i in user_rec_df_reviews['app_id']]\n",
    "\n",
    "user_index_prepped = user_rec_df_prepped['author.steamid'].map(user_map_prepped, na_action='ignore').fillna(-1).astype(int)\n",
    "game_index_prepped = [game_map_prepped[i] for i in user_rec_df_prepped['app_id']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b972d595",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creates csr matrixes\n",
    "matrix_reviews = csr_matrix((user_rec_df_reviews[\"recommended\"], (game_index_reviews, user_index_reviews)), shape=(n_games_reviews, n_users_reviews))\n",
    "matrix_prepped = csr_matrix((user_rec_df_prepped[\"recommended\"], (game_index_prepped, user_index_prepped)), shape=(n_games_prepped, n_users_prepped))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9d286ac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a dictionary to pull the name of games from based on IDs\n",
    "game_names_reviews = dict(zip(df_reviews['app_id'], df_reviews['app_name']))\n",
    "game_names_prepped = dict(zip(df_reviews_dummies['app_id'], df_reviews_dummies['app_name']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "460ff642",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "This function uses both datasets to determine the best match for returning a list of games.  It uses KNN\n",
    "along with the cosine function to find similiaries and store them into a list of neighbor ids.  These ids\n",
    "are then compared for accuracy and the highest matches are returned.\n",
    "\n",
    "@param game_id: the id that references the game found with Steam.\n",
    "@param total_matches: the total number of matches to return\n",
    "@param usePrepped: boolean value to determine if usePrepped should be used in this test model.\n",
    "'''\n",
    "def find_related_games(game_id, total_matches, usePrepped):\n",
    "    \n",
    "    # Set variables\n",
    "    reviews_neighbour_ids_with_distance = {}\n",
    "    \n",
    "    # Prepare index/vectorizations.\n",
    "    game_index_reviews = game_map_reviews[game_id]\n",
    "    game_vector_reviews = matrix_reviews[game_index_reviews]\n",
    "    \n",
    "    # Increment total matches.\n",
    "    total_matches += 1\n",
    "    \n",
    "    # Set the KNN model and fit them.\n",
    "    kNN_reviews = NearestNeighbors(algorithm = 'brute', metric='cosine')\n",
    "    kNN_reviews.fit(matrix_reviews)\n",
    "    \n",
    "    # reshape and determine distances for KNN values.\n",
    "    game_vec_reshaped_reviews = game_vector_reviews.reshape(1,-1)\n",
    "    distances_reviews, indices_reviews = kNN_reviews.kneighbors(game_vec_reshaped_reviews, n_neighbors=total_matches)\n",
    "    \n",
    "    # Loop through and flatten the distances provided\n",
    "    for i in range(0,len(distances_reviews.flatten())):\n",
    "        n = indices_reviews.flatten()[i]\n",
    "        neighbour_id = game_i_map_reviews[n]\n",
    "        reviews_neighbour_ids_with_distance[game_names_reviews[neighbour_id]] = distances_reviews.flatten()[i]\n",
    "    reviews_neighbour_ids_with_distance.pop(game_names_reviews[game_id], None) # removes the same game\n",
    "    \n",
    "    # Sort the data by accuracy\n",
    "    sorted_neighbour_ids_with_distance_reviews = sorted(reviews_neighbour_ids_with_distance.items(), key=lambda x: x[1], reverse=True)\n",
    "    if usePrepped:\n",
    "        sorted_neighbour_ids_with_distance_prepped = find_related_games_usePrepped(game_id, total_matches)\n",
    "    else:\n",
    "        sorted_neighbour_ids_with_distance_prepped = []\n",
    "        \n",
    "    # finalize the list amongst the two created.\n",
    "    combined_list = sorted_neighbour_ids_with_distance_reviews + sorted_neighbour_ids_with_distance_prepped\n",
    "    sorted_combined_list = sorted(combined_list, key=lambda x: x[1])\n",
    "    \n",
    "    # Print the games and their related accuracy.\n",
    "    count = 1\n",
    "    \n",
    "    print(f\"Games related to: {game_names_reviews[game_id]}\\n\")\n",
    "    for game_name, accuracy in sorted_combined_list:\n",
    "        if count == total_matches:\n",
    "            break\n",
    "        else:\n",
    "            print(f\"{game_name}: {accuracy:.2f}\")\n",
    "            count += 1\n",
    "\n",
    "'''\n",
    "This method breaks the logic into a separate function to keep the prior function clean of unnecessary if statements.\n",
    "returns a sorted neighbor_ids list.\n",
    "'''\n",
    "def find_related_games_usePrepped(game_id, total_matches):\n",
    "    prepped_neighbour_ids_with_distance = {}\n",
    "    \n",
    "    # Prepare index/vectorizations.\n",
    "    game_index_prepped = game_map_prepped[game_id]\n",
    "    game_vector_prepped = matrix_prepped[game_index_prepped]\n",
    "    \n",
    "    # Set the KNN model and fit them.\n",
    "    kNN_prepped = NearestNeighbors(algorithm = 'brute', metric='cosine')\n",
    "    kNN_prepped.fit(matrix_prepped)\n",
    "    \n",
    "    # reshape and determine distances for KNN values.\n",
    "    game_vec_reshaped_prepped = game_vector_prepped.reshape(1,-1)\n",
    "    distances_prepped, indices_prepped = kNN_prepped.kneighbors(game_vec_reshaped_prepped, n_neighbors=total_matches)\n",
    "    \n",
    "    # Loop through and flatten the distances provided\n",
    "    for i in range(0,len(distances_prepped.flatten())):\n",
    "        n = indices_prepped.flatten()[i]\n",
    "        neighbour_id = game_i_map_prepped[n]\n",
    "        prepped_neighbour_ids_with_distance[game_names_prepped[neighbour_id]] = distances_prepped.flatten()[i]\n",
    "    prepped_neighbour_ids_with_distance.pop(game_names_prepped[game_id], None)\n",
    "    \n",
    "    # Sort the results.\n",
    "    sorted_neighbour_ids_with_distance_prepped = sorted(prepped_neighbour_ids_with_distance.items(), key=lambda x: x[1])\n",
    "    \n",
    "    return sorted_neighbour_ids_with_distance_prepped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "38f7c972",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Games related to: The Witcher 3: Wild Hunt\n",
      "\n",
      "DARK SOULS™ III: 0.92\n",
      "Rise of the Tomb Raider: 0.92\n",
      "Dying Light: 0.93\n",
      "Grand Theft Auto V: 0.93\n",
      "Fallout 4: 0.93\n"
     ]
    }
   ],
   "source": [
    "# Set a test game id and run the function.\n",
    "game_id = 292030\n",
    "total_matches = 5\n",
    " \n",
    "find_related_games(game_id, total_matches, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4e33bbca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Games related to: The Witcher 3: Wild Hunt\n",
      "\n",
      "Fallout 4: 0.92\n",
      "DARK SOULS™ III: 0.92\n",
      "Rise of the Tomb Raider: 0.92\n",
      "DOOM: 0.93\n",
      "Dying Light: 0.93\n"
     ]
    }
   ],
   "source": [
    "# Set a test game id and run the function.\n",
    "game_id = 292030\n",
    "total_matches = 5\n",
    " \n",
    "find_related_games(game_id, total_matches, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e161886f",
   "metadata": {},
   "source": [
    "The initial model above uses data from two separate datasets to return the lowest accuracies provided by each; a lower accuracy indicates less distance between each game for the KNN model.  This method uses information that we can verify through our individual understanding of the games listed to reinforce whether our model is matching in a way that we think is acceptable (this step is a little more subjective since without playing the games listed, it can be difficult to determine if this is an accurate assessment).  Whether the prepped data is true or false, the result set is matching.  This indicates that both sets when coupled together will predict similarly and that we have a model can use for comparison.  \n",
    "  \n",
    "  For clarity, the game chosen, Witcher 3, is a 3D open world role-playing game where a user travels and completes various missions for money or resources.  In addition to the main linear storyline, there are additional side quests to complete as well.  In the five games returned above, each of the main details described for Witcher 3 are identical (3D, open world, free roam, etc.)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8b375db7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the td-idf vectorizer. \n",
    "tfidfvec = TfidfVectorizer()\n",
    "\n",
    "# Fit the model \n",
    "tfidf_gamedesc = tfidfvec.fit_transform((df_steam_games['prepped_description_lemm'].values.astype('U')))\n",
    "\n",
    "# Add cosine similarity\n",
    "cos_sim = cosine_similarity(tfidf_gamedesc, tfidf_gamedesc)\n",
    "\n",
    "# functions for retrieving similar game IDs from cos_sim\n",
    "indices = pd.Series(df_steam_games.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8ee47357",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Create a new function to get the data by the game's descriptions.\n",
    "Returns a list of recommended games from the model.\n",
    "\n",
    "@param: id: id of the game to get recommendations on.\n",
    "@param: total_matches: total number of matches to return.\n",
    "'''\n",
    "def get_related_games_by_desc(id, total_matches):\n",
    "    \n",
    "    # Set a new dataframe to return.\n",
    "    recommended_games =  pd.DataFrame()\n",
    "    \n",
    "    # Set the index variable.\n",
    "    index = indices[indices == id].index[0]\n",
    "    \n",
    "    # Increment total_matches to be 1 higher.\n",
    "    total_matches += 1\n",
    "    \n",
    "    # Obtain the list of cosine similiarities and set them into a series.\n",
    "    similarity_scores = pd.Series(cos_sim[index]).sort_values(ascending = False)\n",
    "    top = list(similarity_scores.iloc[1:total_matches].index)\n",
    "    recommended_games['Score'] = similarity_scores.iloc[1:total_matches]\n",
    "    \n",
    "    # Create a new list.\n",
    "    app_ids = []\n",
    "    \n",
    "    # Loop over and set the top items in the list.\n",
    "    for i in top:\n",
    "        app_ids.append(list(df_steam_games.index)[i])\n",
    "    recommended_games['App ID'] = app_ids\n",
    "    \n",
    "    print(f\"Games related to: {df_steam_games.loc[df_steam_games.index == game_id].Name.values[0]}\\n\")\n",
    "    for i, val in enumerate(recommended_games[\"App ID\"]):\n",
    "        print(f\"{df_steam_games.loc[df_steam_games.index == val].Name.values[0]}: {recommended_games.Score.values[i]:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e2422b17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Games related to: Age of Empires II (2013)\n",
      "\n",
      "Age of Mythology: Extended Edition: 0.37\n",
      "Rise of Nations: Extended Edition: 0.37\n",
      "Spades: 0.26\n",
      "Spectre: 0.23\n",
      "Escape Legacy: Ancient Scrolls: 0.22\n",
      "DRAKERZ-Confrontation: 0.21\n",
      "Project Beril / 贝丽尔养成计划: 0.21\n",
      "Age of Empires II: Definitive Edition: 0.21\n",
      "Age of Wonders II: The Wizard's Throne: 0.21\n",
      "Akin: 0.20\n"
     ]
    }
   ],
   "source": [
    "# Test the new tdidf model.\n",
    "game_id = 221380\n",
    "total_matches = 10\n",
    "\n",
    "recommended_games = get_related_games_by_desc(game_id, total_matches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d26717a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Games related to: Counter-Strike\n",
      "\n",
      "Rise Of A Hero: 0.23\n",
      "Operation swat: 0.23\n",
      "BLACK CLOVER: QUARTET KNIGHTS: 0.22\n",
      "Emily: Displaced: 0.22\n",
      "Team Fortress Classic: 0.21\n",
      "Rescue Party: Live!: 0.21\n",
      "Werewolves Online: 0.21\n",
      "Firefight!: 0.20\n",
      "Audio Drive: 0.20\n",
      "Infection: 0.20\n"
     ]
    }
   ],
   "source": [
    "# Test the new tdidf model.\n",
    "game_id = 10\n",
    "total_matches = 10\n",
    "\n",
    "recommended_games = get_related_games_by_desc(game_id, total_matches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d3b70a12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Games related to: Panzer Crew VR\n",
      "\n",
      "Steel Crew: 0.60\n",
      "Tank Maniacs: 0.47\n",
      "Tank Commander: Battlefield: 0.47\n",
      "Steel Armor: Blaze of War: 0.46\n",
      "Pocket Tank: 0.46\n",
      "YUT YUT: 0.45\n",
      "Tiger Tank 59 A-Gun: 0.44\n",
      "Armored Battle Crew [World War 1] - Tank Warfare and Crew Management Simulator: 0.44\n",
      "Panzer Panic VR: 0.44\n",
      "Tank Force: 0.43\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Test the new tdidf model.\n",
    "game_id = 1271600\n",
    "total_matches = 10\n",
    "\n",
    "recommended_games = get_related_games_by_desc(game_id, total_matches)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f598d384",
   "metadata": {},
   "source": [
    "#### Interpret your results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b44c1e41",
   "metadata": {},
   "source": [
    "We decided that matrix factorization would be the best solution for both our content-based and collaborative filtering methods while finding a number of successful recommendations using both methods.  Additionally, both methods utilized cosine distance as a measure of likeness to other games.  For our collaborative model we used K-Nearest Neighbors (KNN) which utilizes cosine distances as a potential metric.  The distance is measured as one minus the cosine similarity, so our results had to be inverted.  The lower number resulted in more similar games while the higher numbers resulted in games with greater dissimilarity.  \n",
    "\n",
    "Our content-based recommendations utilized a TFIDFVectorized matrix of game descriptions to calculate it’s cosine similarity.  Unlike the KNN model, we did not have to reverse our list to accommodate for distance, and solely compared similarities with the highest similarities representing the most related games.  Moreover, we did not use a separate dataset to compare our results with the TFIDF model.  Regardless, both models provide results that can be useful for differing purposes.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c9550b9",
   "metadata": {},
   "source": [
    "#### Begin to formulate a conclusion/recommendations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7c23a2c",
   "metadata": {},
   "source": [
    "Our goal was to provide the best models for a number of different use cases, so we couldn’t rely solely on one for each implementation.  Our recommendation is that individual game pages can utilize our content-based solution — the TFIDFVectorized matrix — as this provides games that have very similar descriptions.  From our results, we would often see expansions for games within our top results.\n",
    "\n",
    "Alternatively, the collaborative solution — the KNN model — can work much more effectively as a recommendation of games on the user's homepage, often showing games that may or may not be related, but share a common purchase pattern across users.\n",
    "  \n",
    "As for recommendations given more time, we would recommend expansions for each type of model.  Our collaborative filtering model could take several games and draw its similarities from them in creating personalized lists for users.  Our content-based filtering model can expand it’s matrices to include both genre and tag information in it’s vectorized data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "301da4a7",
   "metadata": {},
   "source": [
    "### Resources"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6845b65a",
   "metadata": {},
   "source": [
    "Kaggle. (n.d.). All 55,000 Games on Steam (November 2022). Www.kaggle.com. Retrieved January 20, 2023, from https://www.kaggle.com/datasets/tristan581/all-55000-games-on-steam-november-2022  \n",
    "\n",
    "M., M. (2021) Steam reviews dataset 2021, Kaggle. Available at: https://www.kaggle.com/datasets/najzeko/steam-reviews-2021?select=steam_reviews.csv (Accessed: December 10, 2022)   \n",
    "\n",
    "Tristan. “All 55,000 Games on Steam (November 2022).” Www.kaggle.com, www.kaggle.com/datasets/tristan581/all-55000-games-on-steam-november-2022."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
